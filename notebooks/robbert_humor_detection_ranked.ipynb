{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Demo of RobBERT for humour ranking\n",
    "\n",
    "If you're looking for the RobBERT joke classification notebook, you probably want [the other notebook: robbert_humor_detection](./robbert_humor_detection.ipynb).\n",
    "\n",
    "This notebook checks how well the RobBERT model trained to distinguish jokes from dynamic templates jokes in **ranked setting** on the whole dataset.\n",
    "This means that given a joke and a corrupted joke, the model should predict which one is the real joke.\n",
    "\n",
    "Note we are running this on the whole datasets for simplicity sake, implying that the the found accuracies are higher than reported in the paper as this notebook also includes the training data instead of only the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import RobertaTokenizer, AutoModelForSequenceClassification, AutoConfig, \\\n",
    "    RobertaForSequenceClassification, InputFeatures"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobBERT model loaded\n"
     ]
    }
   ],
   "source": [
    "model_location = \"../models/jokes-dt-ranked/artifacts/\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_location, model_max_length=512)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_location, return_dict=True)\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda:0')\n",
    "\n",
    "model.eval()\n",
    "print(\"RobBERT model loaded\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with open(\"../data/processed/jokes.json\", encoding=\"utf-8\") as json_file:\n",
    "    jokes = json.load(json_file)\n",
    "with open(\"../data/processed/dynamic_template_jokes.json\", encoding=\"utf-8\") as json_file:\n",
    "    dt = json.load(json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating statistics\n",
    "\n",
    "Create a function to calculate how many are labeled as what"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def tokenize_sentences(left_sentences,\n",
    "                 right_sentences,\n",
    "                 block_size=512,\n",
    "                 mask_padding_with_zero=True):\n",
    "    result = []\n",
    "    for left, right in zip(left_sentences, right_sentences):\n",
    "        tokenized_text = tokenizer.encode(tokenizer.tokenize(left),\n",
    "                                          text_pair=tokenizer.tokenize(right),\n",
    "                                          truncation=True,\n",
    "                                          max_length=block_size,\n",
    "                                          padding=False\n",
    "                                          # padding='max_length'\n",
    "                                          )\n",
    "\n",
    "\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(tokenized_text)\n",
    "        pad_token = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "\n",
    "        while len(tokenized_text) < block_size:\n",
    "            tokenized_text.append(pad_token)\n",
    "            input_mask.append(0 if mask_padding_with_zero else 1)\n",
    "\n",
    "        result.append(\n",
    "            {\n",
    "                \"input_ids\": Tensor(tokenized_text[0: block_size]),\n",
    "                \"attention_mask\": Tensor(input_mask[0: block_size]),\n",
    "            }\n",
    "        )\n",
    "    return result\n",
    "\n",
    "batch_size = 20\n",
    "def label_sentences(left_sentences: List[str], right_sentences: List[str]):\n",
    "\n",
    "    predicted_ids = []\n",
    "\n",
    "    dataset = tokenize_sentences(left_sentences, right_sentences)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in enumerate(dataloader):\n",
    "\n",
    "            # Print a marker every 50 batches\n",
    "            if i % 50 == 0:\n",
    "                print(\"Starting batch\", i)\n",
    "\n",
    "            # Put batch on GPU\n",
    "            if torch.cuda.is_available():\n",
    "                for k, v in inputs.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        inputs[k] = v.to('cuda:0').long()\n",
    "\n",
    "            # Calculate predictions\n",
    "            results = model(**inputs)\n",
    "\n",
    "            # Map to a concrete prediction & log\n",
    "            predicted_ids.extend(results.logits.argmax(axis=1))\n",
    "\n",
    "    num_left = len([i for i in predicted_ids if i == 1])\n",
    "    num_right = len([i for i in predicted_ids if i == 0])\n",
    "\n",
    "    return {\n",
    "        \"Left is joke\": num_left,\n",
    "        \"Right is joke\": num_right,\n",
    "        \"% Left Jokes\": num_left / len(left_sentences),\n",
    "        \"% Right\": num_right / len(left_sentences),\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch 0\n",
      "Starting batch 50\n",
      "Starting batch 100\n",
      "Starting batch 150\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Left is joke': 2550,\n 'Right is joke': 685,\n '% Left Jokes': 0.7882534775888718,\n '% Right': 0.2117465224111283}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should predict high number of jokes on the left\n",
    "label_sentences(jokes, dt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch 0\n",
      "Starting batch 50\n",
      "Starting batch 100\n",
      "Starting batch 150\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Left is joke': 411,\n 'Right is joke': 2824,\n '% Left Jokes': 0.12704791344667696,\n '% Right': 0.872952086553323}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse: Should predict high number of jokes on the right\n",
    "label_sentences(dt, jokes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}